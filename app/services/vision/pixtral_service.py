# app/services/vision/pixtral_service.py
"""
Service d'analyse d'images avec Pixtral - HemersonAIBuild PlaygroundV1
Support multimodal avanc√© avec optimisations pour Chainlit 2.5.5
"""

import asyncio
import time
import base64
import hashlib
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
import tempfile
from PIL import Image, ImageOps
import io
import aiofiles
import httpx
from loguru import logger

from services.rate_limiter.advanced_limiter import CacheManager, RequestType
from config.settings import settings

class PixtralVisionService:
    """
    Service d'analyse d'images avec Pixtral - Optimis√© pour production
    
    Fonctionnalit√©s avanc√©es :
    - Support des tailles d'images variables (native resolution)
    - Analyse multimodale texte + image
    - Cache intelligent des analyses
    - Pr√©processing d'images optimis√©
    - M√©tadonn√©es enrichies
    - Gestion d'erreurs robuste
    """
    
    def __init__(self, cache_manager: CacheManager):
        self.cache_manager = cache_manager
        self.pixtral_endpoint = settings.PIXTRAL_ENDPOINT
        
        # Client HTTP optimis√© pour les images
        self.vision_client = httpx.AsyncClient(
            timeout=httpx.Timeout(
                connect=15.0,
                read=240.0,  # Timeout plus long pour l'analyse d'images
                write=180.0,
                pool=360.0
            ),
            limits=httpx.Limits(
                max_keepalive_connections=10,
                max_connections=30,
                keepalive_expiry=120.0
            )
        )
        
        # Configuration de traitement d'images
        self.image_config = {
            "max_size_mb": 25,
            "supported_formats": ["JPEG", "PNG", "WEBP", "GIF", "BMP"],
            "max_resolution": (2048, 2048),  # Pixtral peut g√©rer des r√©solutions variables
            "quality_optimization": True,
            "auto_orient": True
        }
        
        # M√©triques sp√©cifiques vision
        self.vision_metrics = {
            "images_analyzed": 0,
            "successful_analyses": 0,
            "preprocessing_time_avg": 0.0,
            "analysis_time_avg": 0.0,
            "cache_hits": 0,
            "format_distributions": {},
            "resolution_stats": {"min": None, "max": None, "avg": 0}
        }
        
        logger.info("üñºÔ∏è PixtralVisionService initialis√© avec support multimodal")
    
    async def analyze_image(self,
                           image_data: bytes,
                           filename: str,
                           prompt: str = "Analyse cette image en d√©tail",
                           analysis_type: str = "comprehensive",
                           use_cache: bool = True,
                           **kwargs) -> Dict[str, Any]:
        """
        Analyse d'image avec Pixtral - Version compl√®te optimis√©e
        
        Args:
            image_data: Donn√©es image en bytes
            filename: Nom du fichier original
            prompt: Prompt d'analyse personnalis√©
            analysis_type: Type d'analyse (comprehensive, technical, creative, document)
            use_cache: Utiliser le cache intelligent
            **kwargs: Param√®tres additionnels
            
        Returns:
            Analyse structur√©e avec m√©tadonn√©es compl√®tes
        """
        analysis_start = time.time()
        self.vision_metrics["images_analyzed"] += 1
        
        try:
            logger.info(f"üñºÔ∏è D√©but analyse image: {filename} (type: {analysis_type})")
            
            # √âtape 1: Validation et pr√©processing
            preprocessing_start = time.time()
            
            validation_result = self._validate_image(image_data, filename)
            if not validation_result["valid"]:
                return {
                    "success": False,
                    "error": validation_result["error"],
                    "analysis": "",
                    "metadata": {"validation_failed": True}
                }
            
            # Pr√©processing intelligent de l'image
            processed_image_data, image_metadata = await self._preprocess_image(
                image_data, 
                filename,
                optimization_level=kwargs.get("optimization_level", "balanced")
            )
            
            preprocessing_time = time.time() - preprocessing_start
            logger.info(f"‚úÖ Pr√©processing termin√© en {preprocessing_time:.2f}s")
            
            # √âtape 2: V√©rification du cache
            if use_cache:
                cache_key = self._generate_image_cache_key(
                    processed_image_data, 
                    prompt, 
                    analysis_type,
                    kwargs
                )
                
                cached_result = await self.cache_manager.get_cached_response(cache_key)
                if cached_result:
                    self.vision_metrics["cache_hits"] += 1
                    logger.info(f"üíæ Analyse depuis cache: {filename}")
                    # Ajouter les m√©tadonn√©es de cette session
                    cached_result["metadata"]["cached"] = True
                    cached_result["metadata"]["cache_timestamp"] = time.time()
                    return cached_result
            
            # √âtape 3: Analyse avec Pixtral
            analysis_start_time = time.time()
            
            # Construire le prompt sp√©cialis√© selon le type d'analyse
            specialized_prompt = self._build_specialized_prompt(
                prompt, 
                analysis_type, 
                image_metadata
            )
            
            # Encoder l'image pour Pixtral
            image_b64 = base64.b64encode(processed_image_data).decode('utf-8')
            
            # Pr√©parer la requ√™te Pixtral
            pixtral_payload = {
                "model": "pixtral",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": specialized_prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_b64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": kwargs.get("max_tokens", 2000),
                "temperature": kwargs.get("temperature", 0.2),
                "stream": False
            }
            
            # Faire l'analyse avec retry
            result = await self._make_vision_request_with_retry(
                f"{self.pixtral_endpoint}/v1/chat/completions",
                pixtral_payload,
                max_retries=2,
                operation=f"pixtral_{analysis_type}"
            )
            
            analysis_time = time.time() - analysis_start_time
            
            if result["success"]:
                analysis_content = result["data"]["choices"][0]["message"]["content"]
                
                # Construire la r√©ponse compl√®te
                complete_result = {
                    "success": True,
                    "analysis": analysis_content,
                    "model": "Pixtral 12B",
                    "gpu": "RTX 4090 (192.168.1.212)",
                    "analysis_type": analysis_type.title(),
                    "original_prompt": prompt,
                    "specialized_prompt": specialized_prompt,
                    "processing_times": {
                        "preprocessing": preprocessing_time,
                        "analysis": analysis_time,
                        "total": time.time() - analysis_start
                    },
                    "metadata": {
                        "filename": filename,
                        "image_metadata": image_metadata,
                        "tokens_used": result["data"]["usage"]["total_tokens"],
                        "cached": False,
                        "analysis_quality": self._assess_analysis_quality(analysis_content),
                        "timestamp": time.time()
                    }
                }
                
                # Mettre en cache avec TTL adapt√©
                if use_cache:
                    cache_ttl = 7200  # 2 heures par d√©faut
                    if analysis_type == "document":
                        cache_ttl = 14400  # 4 heures pour documents (plus stable)
                    
                    await self.cache_manager.cache_response(
                        cache_key,
                        complete_result,
                        ttl=cache_ttl
                    )
                
                # Mettre √† jour les m√©triques
                self._update_vision_metrics(True, preprocessing_time, analysis_time, image_metadata)
                self.vision_metrics["successful_analyses"] += 1
                
                logger.info(f"‚úÖ Analyse Pixtral r√©ussie: {filename} ({analysis_time:.2f}s)")
                
                return complete_result
            else:
                self._update_vision_metrics(False, preprocessing_time, 0, image_metadata)
                return {
                    "success": False,
                    "error": result["error"],
                    "analysis": "Erreur lors de l'analyse d'image avec Pixtral.",
                    "model": "Pixtral 12B",
                    "processing_times": {
                        "preprocessing": preprocessing_time,
                        "total": time.time() - analysis_start
                    }
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse Pixtral: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": f"Erreur lors de l'analyse d'image: {str(e)}",
                "model": "Pixtral 12B",
                "processing_times": {
                    "total": time.time() - analysis_start
                }
            }
    
    def _validate_image(self, image_data: bytes, filename: str) -> Dict[str, Any]:
        """Validation compl√®te d'une image"""
        try:
            # V√©rifier la taille
            if len(image_data) > self.image_config["max_size_mb"] * 1024 * 1024:
                return {
                    "valid": False,
                    "error": f"Image trop volumineuse: {len(image_data) / (1024*1024):.1f}MB (max: {self.image_config['max_size_mb']}MB)"
                }
            
            # V√©rifier si c'est une image valide
            try:
                with Image.open(io.BytesIO(image_data)) as img:
                    # V√©rifier le format
                    if img.format not in self.image_config["supported_formats"]:
                        return {
                            "valid": False,
                            "error": f"Format non support√©: {img.format}. Formats accept√©s: {', '.join(self.image_config['supported_formats'])}"
                        }
                    
                    # V√©rifier les dimensions
                    width, height = img.size
                    max_w, max_h = self.image_config["max_resolution"]
                    
                    if width > max_w or height > max_h:
                        logger.warning(f"Image grande r√©solution d√©tect√©e: {width}x{height}")
                    
                    # V√©rifier l'int√©grit√©
                    img.verify()
                    
                    return {
                        "valid": True,
                        "format": img.format,
                        "size": (width, height),
                        "mode": img.mode
                    }
                    
            except Exception as img_error:
                return {
                    "valid": False,
                    "error": f"Image corrompue ou invalide: {str(img_error)}"
                }
                
        except Exception as e:
            return {
                "valid": False,
                "error": f"Erreur de validation: {str(e)}"
            }
    
    async def _preprocess_image(self, 
                               image_data: bytes, 
                               filename: str,
                               optimization_level: str = "balanced") -> Tuple[bytes, Dict[str, Any]]:
        """
        Pr√©processing intelligent d'image pour Pixtral
        
        Args:
            image_data: Donn√©es image originales
            filename: Nom du fichier
            optimization_level: Niveau d'optimisation (fast, balanced, quality)
            
        Returns:
            (processed_image_data, metadata)
        """
        try:
            with Image.open(io.BytesIO(image_data)) as img:
                # M√©tadonn√©es originales
                original_metadata = {
                    "original_format": img.format,
                    "original_size": img.size,
                    "original_mode": img.mode,
                    "original_bytes": len(image_data)
                }
                
                # Conversion RGBA -> RGB si n√©cessaire (pour JPEG)
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                    img = background
                
                # Auto-orientation (EXIF)
                if self.image_config["auto_orient"]:
                    img = ImageOps.exif_transpose(img)
                
                # Optimisation selon le niveau
                processed_img = self._apply_optimization(img, optimization_level)
                
                # Sauvegarder en m√©moire
                output_buffer = io.BytesIO()
                
                # Format et qualit√© optimaux pour Pixtral
                if optimization_level == "quality":
                    processed_img.save(output_buffer, format='JPEG', quality=95, optimize=True)
                elif optimization_level == "fast":
                    processed_img.save(output_buffer, format='JPEG', quality=75, optimize=True)
                else:  # balanced
                    processed_img.save(output_buffer, format='JPEG', quality=85, optimize=True)
                
                processed_data = output_buffer.getvalue()
                
                # M√©tadonn√©es compl√®tes
                metadata = {
                    **original_metadata,
                    "processed_format": "JPEG",
                    "processed_size": processed_img.size,
                    "processed_bytes": len(processed_data),
                    "compression_ratio": len(image_data) / len(processed_data),
                    "optimization_level": optimization_level,
                    "aspect_ratio": processed_img.size[0] / processed_img.size[1],
                    "pixel_count": processed_img.size[0] * processed_img.size[1]
                }
                
                return processed_data, metadata
                
        except Exception as e:
            logger.error(f"‚ùå Erreur preprocessing: {e}")
            # En cas d'erreur, retourner l'image originale
            return image_data, {
                "preprocessing_failed": True,
                "error": str(e),
                "fallback_to_original": True
            }
    
    def _apply_optimization(self, img: Image.Image, level: str) -> Image.Image:
        """Applique les optimisations selon le niveau"""
        try:
            width, height = img.size
            max_w, max_h = self.image_config["max_resolution"]
            
            if level == "fast":
                # Redimensionnement agressif si n√©cessaire
                if width > max_w or height > max_h:
                    img.thumbnail((max_w, max_h), Image.Resampling.LANCZOS)
                
            elif level == "quality":
                # Pr√©server la qualit√© autant que possible
                if width > max_w * 1.5 or height > max_h * 1.5:
                    img.thumbnail((max_w, max_h), Image.Resampling.LANCZOS)
                
            else:  # balanced
                # Optimisation √©quilibr√©e
                if width > max_w or height > max_h:
                    img.thumbnail((max_w, max_h), Image.Resampling.LANCZOS)
            
            return img
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur optimisation image: {e}")
            return img
    
    def _build_specialized_prompt(self, 
                                 base_prompt: str, 
                                 analysis_type: str,
                                 image_metadata: Dict[str, Any]) -> str:
        """Construit un prompt sp√©cialis√© selon le type d'analyse"""
        
        # Contexte sur l'image
        img_context = f"Image: {image_metadata.get('processed_size', 'R√©solution inconnue')}, "
        img_context += f"format: {image_metadata.get('original_format', 'inconnu')}"
        
        prompts_templates = {
            "comprehensive": f"""Tu es Pixtral, expert en analyse d'images multimodale.

{img_context}

Effectue une analyse COMPL√àTE et STRUCTUR√âE de cette image selon ce prompt : "{base_prompt}"

Structure ta r√©ponse EXACTEMENT ainsi :

üîç **DESCRIPTION G√âN√âRALE**
- Sujet principal et √©l√©ments secondaires
- Composition, cadrage et perspective
- Style artistique ou photographique

üé® **ANALYSE VISUELLE D√âTAILL√âE**
- Couleurs dominantes et palette chromatique
- Textures, mati√®res et surfaces
- √âclairage, ombres et atmosph√®re
- Qualit√© technique de l'image

üìä **ANALYSE TECHNIQUE**
- Technique de cr√©ation (photo, dessin, rendu, etc.)
- Qualit√© et r√©solution observ√©e
- √âl√©ments techniques remarquables
- Post-traitement apparent

üß† **INTERPR√âTATION CONTEXTUELLE**
- Contexte historique, culturel ou social
- Message ou signification possible
- R√©f√©rences artistiques ou culturelles
- √âmotion ou sentiment transmis

üí° **OBSERVATIONS SP√âCIALIS√âES**
- D√©tails fins ou √©l√©ments cach√©s
- Aspects inhabituels ou remarquables
- Analyse de la composition avanc√©e
- Suggestions d'am√©lioration si pertinentes

Sois pr√©cis, d√©taill√© et analytique. Utilise tes capacit√©s de vision avanc√©es.""",

            "technical": f"""Tu es Pixtral en mode EXPERT TECHNIQUE.

{img_context}

Analyse technique approfondie : "{base_prompt}"

FOCUS sur :
- Aspects techniques de l'image
- Qualit√©, r√©solution, compression
- Techniques de cr√©ation utilis√©es
- D√©fauts ou probl√®mes techniques
- Optimisations possibles
- M√©tadonn√©es visuelles d√©tectables

Sois technique et pr√©cis.""",

            "creative": f"""Tu es Pixtral en mode CR√âATIF.

{img_context}

Analyse cr√©ative : "{base_prompt}"

EXPLORE :
- Aspects artistiques et esth√©tiques
- Cr√©ativit√© et originalit√©
- Inspiration et influences
- Potentiel cr√©atif
- Suggestions d'am√©lioration artistique
- Variations possibles

Sois cr√©atif et inspirant.""",

            "document": f"""Tu es Pixtral, expert en analyse de DOCUMENTS.

{img_context}

Analyse de document : "{base_prompt}"

STRUCTURE pour documents :
- Type de document identifi√©
- Texte visible (transcription si possible)
- Structure et mise en page
- Qualit√© de lisibilit√©
- Informations extraites
- Conseils d'optimisation pour OCR

Sois m√©thodique et pr√©cis pour l'extraction d'informations."""
        }
        
        return prompts_templates.get(analysis_type, prompts_templates["comprehensive"])
    
    def _generate_image_cache_key(self, 
                                 image_data: bytes, 
                                 prompt: str,
                                 analysis_type: str, 
                                 params: Dict) -> str:
        """G√©n√®re une cl√© de cache unique pour l'image"""
        # Hash de l'image
        image_hash = hashlib.md5(image_data).hexdigest()[:16]
        
        # Hash du prompt et param√®tres
        prompt_data = f"{prompt}_{analysis_type}_{sorted(params.items())}"
        prompt_hash = hashlib.md5(prompt_data.encode()).hexdigest()[:16]
        
        return f"pixtral_vision:{image_hash}:{prompt_hash}"
    
    def _assess_analysis_quality(self, analysis_content: str) -> Dict[str, Any]:
        """√âvalue la qualit√© de l'analyse produite"""
        try:
            # M√©triques de qualit√©
            content_length = len(analysis_content)
            word_count = len(analysis_content.split())
            paragraph_count = analysis_content.count('\n\n') + 1
            structured_sections = analysis_content.count('**')
            
            # Score de qualit√© bas√© sur plusieurs facteurs
            length_score = min(content_length / 1000, 1.0)  # Optimal vers 1000 chars
            structure_score = min(structured_sections / 10, 1.0)  # Sections structur√©es
            detail_score = min(word_count / 200, 1.0)  # D√©tail suffisant
            
            overall_quality = (length_score * 0.3 + structure_score * 0.4 + detail_score * 0.3)
            
            # Classification qualitative
            if overall_quality >= 0.8:
                quality_label = "excellent"
            elif overall_quality >= 0.6:
                quality_label = "good"
            elif overall_quality >= 0.4:
                quality_label = "fair"
            else:
                quality_label = "poor"
            
            return {
                "overall_score": overall_quality,
                "quality_label": quality_label,
                "content_length": content_length,
                "word_count": word_count,
                "structure_score": structure_score,
                "detail_level": detail_score
            }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur √©valuation qualit√©: {e}")
            return {"overall_score": 0.5, "quality_label": "unknown"}
    
    async def _make_vision_request_with_retry(self, 
                                             endpoint: str,
                                             payload: Dict[str, Any],
                                             max_retries: int = 3,
                                             operation: str = "vision_request") -> Dict[str, Any]:
        """Requ√™te HTTP sp√©cialis√©e pour la vision avec retry"""
        
        for attempt in range(max_retries):
            try:
                response = await self.vision_client.post(
                    endpoint,
                    json=payload,
                    timeout=180  # 3 minutes pour analyse d'images
                )
                
                if response.status_code == 200:
                    return {"success": True, "data": response.json()}
                else:
                    logger.warning(f"‚ö†Ô∏è HTTP {response.status_code} pour {operation} (tentative {attempt + 1})")
                    
            except httpx.TimeoutException:
                logger.warning(f"‚è∞ Timeout {operation} (tentative {attempt + 1})")
            except Exception as e:
                logger.error(f"‚ùå Erreur {operation}: {e}")
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                logger.info(f"‚è≥ Attente {wait_time}s avant retry {operation}...")
                await asyncio.sleep(wait_time)
        
        return {
            "success": False,
            "error": f"√âchec {operation} apr√®s {max_retries} tentatives"
        }
    
    def _update_vision_metrics(self, 
                              success: bool, 
                              preprocessing_time: float,
                              analysis_time: float, 
                              image_metadata: Dict[str, Any]):
        """Met √† jour les m√©triques de vision"""
        
        # Temps de pr√©processing
        current_prep_avg = self.vision_metrics["preprocessing_time_avg"]
        total_images = self.vision_metrics["images_analyzed"]
        self.vision_metrics["preprocessing_time_avg"] = (
            (current_prep_avg * (total_images - 1) + preprocessing_time) / total_images
        )
        
        if success and analysis_time > 0:
            # Temps d'analyse
            current_analysis_avg = self.vision_metrics["analysis_time_avg"]
            successful_count = self.vision_metrics["successful_analyses"] + 1
            self.vision_metrics["analysis_time_avg"] = (
                (current_analysis_avg * (successful_count - 1) + analysis_time) / successful_count
            )
        
        # Distribution des formats
        original_format = image_metadata.get("original_format", "unknown")
        if original_format in self.vision_metrics["format_distributions"]:
            self.vision_metrics["format_distributions"][original_format] += 1
        else:
            self.vision_metrics["format_distributions"][original_format] = 1
        
        # Statistiques de r√©solution
        pixel_count = image_metadata.get("pixel_count", 0)
        if pixel_count > 0:
            if self.vision_metrics["resolution_stats"]["min"] is None:
                self.vision_metrics["resolution_stats"]["min"] = pixel_count
                self.vision_metrics["resolution_stats"]["max"] = pixel_count
            else:
                self.vision_metrics["resolution_stats"]["min"] = min(
                    self.vision_metrics["resolution_stats"]["min"], pixel_count
                )
                self.vision_metrics["resolution_stats"]["max"] = max(
                    self.vision_metrics["resolution_stats"]["max"], pixel_count
                )
            
            # Moyenne mobile
            current_avg = self.vision_metrics["resolution_stats"]["avg"]
            self.vision_metrics["resolution_stats"]["avg"] = (
                (current_avg * (total_images - 1) + pixel_count) / total_images
            )
    
    async def get_vision_metrics(self) -> Dict[str, Any]:
        """Retourne les m√©triques de vision d√©taill√©es"""
        success_rate = 0
        if self.vision_metrics["images_analyzed"] > 0:
            success_rate = (
                self.vision_metrics["successful_analyses"] / 
                self.vision_metrics["images_analyzed"]
            ) * 100
        
        cache_hit_rate = 0
        if self.vision_metrics["images_analyzed"] > 0:
            cache_hit_rate = (
                self.vision_metrics["cache_hits"] / 
                self.vision_metrics["images_analyzed"]
            ) * 100
        
        return {
            **self.vision_metrics,
            "success_rate_percent": success_rate,
            "cache_hit_rate_percent": cache_hit_rate,
            "avg_image_resolution": self.vision_metrics["resolution_stats"]["avg"],
            "most_common_format": max(
                self.vision_metrics["format_distributions"], 
                key=self.vision_metrics["format_distributions"].get
            ) if self.vision_metrics["format_distributions"] else "unknown"
        }
    
    async def close(self):
        """Fermeture propre du service"""
        await self.vision_client.aclose()
        logger.info("üîå PixtralVisionService ferm√© proprement")

# Instance globale
pixtral_service = PixtralVisionService(cache_manager)
